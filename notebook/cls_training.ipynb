{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import libraries\n",
    "# MIT License\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix,\\\n",
    "roc_auc_score, roc_curve, precision_recall_curve, fbeta_score, recall_score,\\\n",
    "precision_recall_fscore_support\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# import classificators\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold \n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# import sampler\n",
    "from imblearn.over_sampling import SMOTE, BorderlineSMOTE, SVMSMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "# K-Nearest Neighbor OveRsampling (KNNOR)\n",
    "from knnor import data_augment\n",
    "\n",
    "# import classificators\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# import regressors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy.special import inv_boxcox\n",
    "\n",
    "# import library for feature engineering\n",
    "# autofeat: Automated Feature Engineering Toolkit\n",
    "# @inproceedings{horn2019autofeat,\n",
    "#   title={The autofeat Python Library for Automated Feature Engineering and Selection},\n",
    "#   author={Horn, Franziska and Pack, Robert and Rieger, Michael},\n",
    "#   booktitle={Joint European Conference on Machine Learning and Knowledge Discovery in Databases},\n",
    "#   pages={111--120},\n",
    "#   year={2019},\n",
    "#   organization={Springer}\n",
    "# }\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, mutual_info_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "from autofeat import FeatureSelector\n",
    "# import system\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import scipy.stats as stats\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# import scalers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sigfig import round\n",
    "import itertools\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_profit(tp, fp, fn, tn, benefit_tp, cost_fp, cost_fn, benefit_tn):\n",
    "    total_profit = (tp * benefit_tp) - (fp * cost_fp) - (fn * cost_fn) + (tn * benefit_tn)\n",
    "    return total_profit\n",
    "\n",
    "def plot_total_profit_bar_chart(keywords,results_df):\n",
    "    # Define cost-benefit parameters\n",
    "    benefit_tp = 60   # Benefit from a True Positive\n",
    "    cost_fp = 40      # Cost of a False Positive\n",
    "    cost_fn = 55      # Cost of a False Negative\n",
    "    benefit_tn = 10   # Benefit of a True Negative\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    total_profits = []\n",
    "\n",
    "    for idx, row in results_df.iterrows():\n",
    "        keyword = row[keywords]\n",
    "\n",
    "        # Extract confusion matrix components\n",
    "        tn, fp = row['Confusion_Matrix'][0]\n",
    "        fn, tp = row['Confusion_Matrix'][1]\n",
    "\n",
    "        # Calculate total profit\n",
    "        total_profit = calculate_profit(tp, fp, fn, tn, benefit_tp, cost_fp, cost_fn, benefit_tn)\n",
    "        total_profits.append((keyword, total_profit))\n",
    "\n",
    "    # Sort feature selectors by total profit for better visualization\n",
    "    total_profits.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Plotting\n",
    "    feature_selectors, profits = zip(*total_profits)\n",
    "    plt.bar(feature_selectors, profits, color='skyblue')\n",
    "    plt.ylabel('Total Estimated Profit')\n",
    "    plt.title('Total Profit Comparison for Different Feature Selectors')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../data/cls/cls_encoder.csv')\n",
    "y = pd.read_csv('../data/cls/cls_target.csv')\n",
    "X_df = pd.DataFrame(X)\n",
    "y_df = pd.DataFrame(y)\n",
    "y_df = y_df.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, model, sampler, feature_selector):\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
    "    \n",
    "    # Scaling the training data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # apply sampler\n",
    "    X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # apply feature selector\n",
    "    X_train_selected = feature_selector.fit_transform(X_train_res, y_train_res)\n",
    "    X_test_selected = feature_selector.transform(X_test_scaled)\n",
    "    \n",
    "    # Check the number of features after selection\n",
    "    n_features = X_train_selected.shape[1]\n",
    "    \n",
    "    if n_features > 1:\n",
    "        # Fit PCA if enough features are available\n",
    "        pca = PCA(n_components=min(n_features, 2))  # Adjust n_components based on available features\n",
    "        X_train_pca = pca.fit_transform(X_train_selected)\n",
    "        X_test_pca = pca.transform(X_test_selected)\n",
    "    else:\n",
    "        # Skip PCA if only one feature is present\n",
    "        X_train_pca = X_train_selected\n",
    "        X_test_pca = X_test_selected\n",
    "\n",
    "    # fit model\n",
    "    model.fit(X_train_pca, y_train_res)\n",
    "    # predict\n",
    "    y_pred = model.predict(X_test_pca)\n",
    "    \n",
    "    # # evaluate\n",
    "    train_score = model.score(X_train_pca, y_train_res)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "    cross_val_scores = cross_val_score(model, X_train_pca, y_train_res, cv=5)\n",
    "    cross_val_mean = cross_val_scores.mean()\n",
    "    aoc_score = roc_auc_score(y_test, y_pred)\n",
    "    \n",
    "    result = {\n",
    "        'training_score': train_score,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'Confusion_Matrix': cm,\n",
    "        'Classification_Report': cr,\n",
    "        'cross_val_scores': cross_val_scores,\n",
    "        'cross_val_mean': cross_val_mean,\n",
    "        'aoc_score': aoc_score\n",
    "    }\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(result):\n",
    "    # Extracting recall and F1-score from classification reports\n",
    "    recall_scores_avg = []\n",
    "    recall_scores_1 = []\n",
    "    f1_scores = []\n",
    "    precision_scores = []\n",
    "    keyword = results_df[keywords].tolist()\n",
    "\n",
    "    for report in result['classification_report']:\n",
    "        recall_scores_avg.append(report['weighted avg']['recall'])\n",
    "        recall_scores_1.append(report['1']['recall'])\n",
    "        f1_scores.append(report['weighted avg']['f1-score'])\n",
    "        precision_scores.append(report['weighted avg']['precision'])\n",
    "\n",
    "    # Creating a DataFrame for visualization\n",
    "    metrics_df = pd.DataFrame({\n",
    "        keywords: keyword,\n",
    "        'Recall on average': recall_scores_avg,\n",
    "        'Recall on default': recall_scores_1,\n",
    "        'F1-Score': f1_scores,\n",
    "        'Precision': precision_scores,\n",
    "        'cross_val_scores': result['cross_val_scores'].tolist()\n",
    "    })\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=keywords, y='value', hue='variable', data=pd.melt(metrics_df, id_vars=keywords))\n",
    "    plt.title('Recall and F1-Score for Different Samplers')\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel(keywords)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Metric')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "# Import other necessary libraries\n",
    "\n",
    "def grid_search_from_scratch(X, y, model, sampler, feature_selector, parameter_grid):\n",
    "    keys, values = zip(*parameter_grid.items())\n",
    "    parameter_combinations = [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    total_combinations = len(parameter_combinations)\n",
    "    report = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for idx, params in enumerate(parameter_combinations):\n",
    "        model.set_params(**params)\n",
    "        results = train_model(X, y, model, sampler, feature_selector)\n",
    "        \n",
    "        report.append({\n",
    "            'params': params,\n",
    "            'results': results\n",
    "        })\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        avg_time_per_iteration = elapsed_time / (idx + 1)\n",
    "        estimated_remaining_time = avg_time_per_iteration * (total_combinations - idx - 1)\n",
    "\n",
    "        sys.stdout.write(f'\\rProgress: {idx + 1}/{total_combinations} (Estimated Time Remaining: {estimated_remaining_time:.2f} seconds)')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    return report\n",
    "\n",
    "final_sampler = SVMSMOTE(random_state=33)\n",
    "final_feature_selector = SelectKBest(f_classif, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sampler = SVMSMOTE(random_state=33)\n",
    "final_feature_selector = SelectKBest(f_classif, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 100/100 (Estimated Time Remaining: 0.00 seconds))"
     ]
    }
   ],
   "source": [
    "parameters_lg = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'max_iter': [100, 200, 400, 500],         # Maximum number of iterations to converge\n",
    "    'penalty': ['l2'],        # Type of regularization\n",
    "    'solver': ['newton-cholesky', 'lbfgs', 'liblinear', 'sag', 'saga'],  # Algorithm to use for optimization\n",
    "    'random_state': [33]\n",
    "}\n",
    "\n",
    "logistic_regression_report = grid_search_from_scratch(X_df, y_df, LogisticRegression(), final_sampler, final_feature_selector, parameters_lg)\n",
    "# save report:\n",
    "import pickle\n",
    "pickle.dump(logistic_regression_report, open('../data/cls/logistic_regression_report.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 35/360 (Estimated Time Remaining: 71843.98 seconds)"
     ]
    }
   ],
   "source": [
    "parameters_svm = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],  # Kernel function to use\n",
    "    'gamma': ['scale', 'auto'],  # Kernel coefficient\n",
    "    'degree': [2, 3, 4],  # Degree of the polynomial kernel function\n",
    "    'cache_size': [700],\n",
    "    'max_iter': [100, 200, -1],         # Maximum number of iterations to converge\n",
    "    'random_state': [33]\n",
    "}\n",
    "\n",
    "svm_report = grid_search_from_scratch(X_df, y_df, SVC(), final_sampler, final_feature_selector, parameters_svm)\n",
    "pickle.dump(svm_report, open('../data/cls/svm_report.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_random_forest = {\n",
    "    'n_estimators': [100, 200, 400, 500],  # Number of trees in the forest\n",
    "    'criterion': ['gini', 'entropy'],  # Function to measure the quality of a split\n",
    "    'max_depth': [None, 10, 20, 50, 100],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "    'bootstrap': [True, False],  # Whether bootstrap samples are used when building trees\n",
    "    'random_state': [33],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "random_forest_report = grid_search_from_scratch(X_df, y_df, RandomForestClassifier(), final_sampler, final_feature_selector, parameters_random_forest)\n",
    "pickle.dump(random_forest_report, open('../data/cls/random_forest_report.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
